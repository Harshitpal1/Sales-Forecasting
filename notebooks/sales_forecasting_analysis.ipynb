{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sales Forecasting Analytics Project\n",
    "\n",
    "## Overview\n",
    "This notebook demonstrates a complete end-to-end sales forecasting solution for retail stores. We'll cover:\n",
    "1. Data exploration and visualization\n",
    "2. Feature engineering with holiday and seasonality features\n",
    "3. Multiple regression models (Linear, Random Forest, Gradient Boosting, XGBoost)\n",
    "4. Model evaluation and comparison\n",
    "5. Feature importance analysis\n",
    "6. Results interpretation and insights\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "from datetime import datetime\n",
    "\n",
    "# Import our custom modules\n",
    "import sys\n",
    "sys.path.append('../src')\n",
    "\n",
    "from data_preprocessing import SalesDataPreprocessor, create_sample_data\n",
    "from models import SalesForecaster\n",
    "from evaluation import ModelEvaluator\n",
    "\n",
    "# Settings\n",
    "warnings.filterwarnings('ignore')\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "%matplotlib inline\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"Setup complete!\")\n",
    "print(f\"Pandas version: {pd.__version__}\")\n",
    "print(f\"NumPy version: {np.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Loading and Initial Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sample sales data\n",
    "# In a real scenario, you would load your data from a CSV file:\n",
    "# df = pd.read_csv('../data/sales_data.csv')\n",
    "\n",
    "print(\"Creating sample sales data...\")\n",
    "df = create_sample_data(num_rows=1000, start_date='2010-01-01')\n",
    "\n",
    "print(f\"\\nDataset shape: {df.shape}\")\n",
    "print(f\"Date range: {df['Date'].min()} to {df['Date'].max()}\")\n",
    "print(f\"\\nFirst few rows:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic statistics\n",
    "print(\"Dataset Statistics:\")\n",
    "print(\"=\"*50)\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "print(\"Missing Values:\")\n",
    "print(\"=\"*50)\n",
    "missing = df.isnull().sum()\n",
    "if missing.sum() == 0:\n",
    "    print(\"No missing values found!\")\n",
    "else:\n",
    "    print(missing[missing > 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sales over time\n",
    "fig, ax = plt.subplots(figsize=(15, 5))\n",
    "ax.plot(df['Date'], df['Weekly_Sales'], alpha=0.7, linewidth=1)\n",
    "ax.set_xlabel('Date', fontsize=12)\n",
    "ax.set_ylabel('Weekly Sales', fontsize=12)\n",
    "ax.set_title('Sales Over Time', fontsize=14, fontweight='bold')\n",
    "ax.grid(True, alpha=0.3)\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sales distribution\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Histogram\n",
    "axes[0].hist(df['Weekly_Sales'], bins=50, edgecolor='black', alpha=0.7)\n",
    "axes[0].set_xlabel('Weekly Sales', fontsize=12)\n",
    "axes[0].set_ylabel('Frequency', fontsize=12)\n",
    "axes[0].set_title('Sales Distribution', fontsize=14, fontweight='bold')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Box plot\n",
    "axes[1].boxplot(df['Weekly_Sales'])\n",
    "axes[1].set_ylabel('Weekly Sales', fontsize=12)\n",
    "axes[1].set_title('Sales Box Plot', fontsize=14, fontweight='bold')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation matrix\n",
    "correlation_matrix = df.select_dtypes(include=[np.number]).corr()\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(correlation_matrix, annot=True, fmt='.2f', cmap='coolwarm', \n",
    "            center=0, square=True, linewidths=1)\n",
    "plt.title('Correlation Matrix', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Feature Engineering\n",
    "\n",
    "Now we'll create comprehensive features including:\n",
    "- Date-based features (day of week, month, quarter, season)\n",
    "- Holiday flags and days to holidays\n",
    "- Lag features\n",
    "- Rolling window statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize preprocessor\n",
    "preprocessor = SalesDataPreprocessor()\n",
    "\n",
    "# Run complete preprocessing pipeline\n",
    "df_processed = preprocessor.preprocess_pipeline(\n",
    "    df=df.copy(),\n",
    "    date_column='Date',\n",
    "    target_column='Weekly_Sales',\n",
    "    handle_outliers_cols=['Weekly_Sales']\n",
    ")\n",
    "\n",
    "print(f\"\\nProcessed dataset shape: {df_processed.shape}\")\n",
    "print(f\"Number of features created: {df_processed.shape[1] - df.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display sample of processed data\n",
    "print(\"Sample of processed data:\")\n",
    "df_processed.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View all created features\n",
    "print(\"All features:\")\n",
    "print(\"=\"*50)\n",
    "for i, col in enumerate(df_processed.columns, 1):\n",
    "    print(f\"{i:2d}. {col}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Seasonality Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sales by day of week\n",
    "if 'DayOfWeek' in df_processed.columns:\n",
    "    day_names = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
    "    weekly_sales = df_processed.groupby('DayOfWeek')['Weekly_Sales'].mean().reset_index()\n",
    "    \n",
    "    plt.figure(figsize=(12, 5))\n",
    "    bars = plt.bar(weekly_sales['DayOfWeek'], weekly_sales['Weekly_Sales'], \n",
    "                   alpha=0.8, edgecolor='black')\n",
    "    \n",
    "    # Color weekend bars differently\n",
    "    for i, bar in enumerate(bars):\n",
    "        if i >= 5:  # Weekend\n",
    "            bar.set_color('coral')\n",
    "        else:\n",
    "            bar.set_color('skyblue')\n",
    "    \n",
    "    plt.xticks(range(7), day_names, rotation=45)\n",
    "    plt.xlabel('Day of Week', fontsize=12)\n",
    "    plt.ylabel('Average Sales', fontsize=12)\n",
    "    plt.title('Average Sales by Day of Week', fontsize=14, fontweight='bold')\n",
    "    plt.grid(True, alpha=0.3, axis='y')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sales by month\n",
    "if 'Month' in df_processed.columns:\n",
    "    month_names = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', \n",
    "                   'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']\n",
    "    monthly_sales = df_processed.groupby('Month')['Weekly_Sales'].mean().reset_index()\n",
    "    \n",
    "    plt.figure(figsize=(12, 5))\n",
    "    plt.plot(monthly_sales['Month'], monthly_sales['Weekly_Sales'], \n",
    "             marker='o', linewidth=2, markersize=8, alpha=0.8)\n",
    "    plt.xticks(range(1, 13), month_names)\n",
    "    plt.xlabel('Month', fontsize=12)\n",
    "    plt.ylabel('Average Sales', fontsize=12)\n",
    "    plt.title('Average Sales by Month (Seasonality)', fontsize=14, fontweight='bold')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sales by season\n",
    "if 'Season' in df_processed.columns:\n",
    "    seasonal_sales = df_processed.groupby('Season')['Weekly_Sales'].agg(['mean', 'std']).reset_index()\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.bar(seasonal_sales['Season'], seasonal_sales['mean'], \n",
    "            yerr=seasonal_sales['std'], alpha=0.8, edgecolor='black', capsize=10)\n",
    "    plt.xlabel('Season', fontsize=12)\n",
    "    plt.ylabel('Average Sales', fontsize=12)\n",
    "    plt.title('Average Sales by Season', fontsize=14, fontweight='bold')\n",
    "    plt.grid(True, alpha=0.3, axis='y')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Holiday Impact Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare sales on holidays vs non-holidays\n",
    "if 'IsHoliday' in df_processed.columns:\n",
    "    holiday_comparison = df_processed.groupby('IsHoliday')['Weekly_Sales'].agg(['mean', 'std', 'count']).reset_index()\n",
    "    holiday_comparison['IsHoliday'] = holiday_comparison['IsHoliday'].map({0: 'Non-Holiday', 1: 'Holiday'})\n",
    "    \n",
    "    print(\"Holiday Impact on Sales:\")\n",
    "    print(\"=\"*50)\n",
    "    print(holiday_comparison)\n",
    "    print()\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.bar(holiday_comparison['IsHoliday'], holiday_comparison['mean'],\n",
    "            yerr=holiday_comparison['std'], alpha=0.8, edgecolor='black', capsize=10)\n",
    "    plt.xlabel('Period', fontsize=12)\n",
    "    plt.ylabel('Average Sales', fontsize=12)\n",
    "    plt.title('Sales Comparison: Holidays vs Non-Holidays', fontsize=14, fontweight='bold')\n",
    "    plt.grid(True, alpha=0.3, axis='y')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sales around specific holidays\n",
    "holiday_cols = [col for col in df_processed.columns if col.startswith('Is') and \n",
    "                'Holiday' in col and col != 'IsHoliday' and col != 'IsPreHoliday' and col != 'IsPostHoliday']\n",
    "\n",
    "if holiday_cols:\n",
    "    holiday_sales = []\n",
    "    for col in holiday_cols:\n",
    "        holiday_name = col.replace('Is', '')\n",
    "        avg_sales = df_processed[df_processed[col] == 1]['Weekly_Sales'].mean()\n",
    "        holiday_sales.append({'Holiday': holiday_name, 'Avg_Sales': avg_sales})\n",
    "    \n",
    "    holiday_sales_df = pd.DataFrame(holiday_sales)\n",
    "    \n",
    "    if len(holiday_sales_df) > 0:\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        plt.bar(holiday_sales_df['Holiday'], holiday_sales_df['Avg_Sales'], \n",
    "                alpha=0.8, edgecolor='black')\n",
    "        plt.xlabel('Holiday', fontsize=12)\n",
    "        plt.ylabel('Average Sales', fontsize=12)\n",
    "        plt.title('Average Sales During Specific Holidays', fontsize=14, fontweight='bold')\n",
    "        plt.xticks(rotation=45, ha='right')\n",
    "        plt.grid(True, alpha=0.3, axis='y')\n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Model Training and Comparison\n",
    "\n",
    "Now we'll train multiple regression models and compare their performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for modeling\n",
    "forecaster = SalesForecaster(random_state=42)\n",
    "\n",
    "# Remove rows with NaN values (from lag features)\n",
    "df_model = df_processed.dropna().reset_index(drop=True)\n",
    "\n",
    "print(f\"Data after removing NaN: {df_model.shape}\")\n",
    "\n",
    "# Prepare train/test split\n",
    "X_train, X_test, y_train, y_test = forecaster.prepare_data(\n",
    "    df=df_model,\n",
    "    target_column='Weekly_Sales',\n",
    "    test_size=0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize and train all models\n",
    "forecaster.initialize_models()\n",
    "trained_models = forecaster.train_all_models(X_train, y_train)\n",
    "\n",
    "# Display training summary\n",
    "print(\"\\nTraining Summary:\")\n",
    "print(forecaster.get_model_summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize evaluator\n",
    "evaluator = ModelEvaluator()\n",
    "\n",
    "# Evaluate each model\n",
    "model_predictions = {}\n",
    "\n",
    "for model_name in trained_models.keys():\n",
    "    print(f\"\\nEvaluating {model_name}...\")\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred = forecaster.predict(model_name, X_test)\n",
    "    model_predictions[model_name] = y_pred\n",
    "    \n",
    "    # Calculate metrics\n",
    "    metrics = evaluator.evaluate_model(y_test, y_pred, model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare all models\n",
    "comparison_df = evaluator.compare_models()\n",
    "comparison_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize model comparison\n",
    "evaluator.plot_model_comparison(comparison_df, metric='RMSE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi-metric comparison\n",
    "evaluator.plot_multiple_metrics_comparison(comparison_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Detailed Analysis of Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get best model (lowest RMSE)\n",
    "best_model_name = comparison_df.index[0]\n",
    "best_predictions = model_predictions[best_model_name]\n",
    "\n",
    "print(f\"Best Model: {best_model_name}\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Generate detailed evaluation report\n",
    "evaluator.generate_evaluation_report(\n",
    "    y_test, \n",
    "    best_predictions, \n",
    "    best_model_name,\n",
    "    save_dir='../results/visualizations'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Feature Importance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze feature importance for tree-based models\n",
    "tree_models = ['Random Forest', 'Gradient Boosting', 'XGBoost']\n",
    "\n",
    "for model_name in tree_models:\n",
    "    if model_name in trained_models:\n",
    "        print(f\"\\nFeature Importance - {model_name}:\")\n",
    "        print(\"=\"*50)\n",
    "        \n",
    "        importance_df = forecaster.get_feature_importance(model_name, top_n=15)\n",
    "        \n",
    "        if importance_df is not None:\n",
    "            print(importance_df)\n",
    "            print()\n",
    "            evaluator.plot_feature_importance(\n",
    "                importance_df, \n",
    "                model_name, \n",
    "                top_n=15,\n",
    "                save_path=f'../results/visualizations/{model_name.replace(\" \", \"_\")}_feature_importance.png'\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Cross-Validation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform cross-validation for all models\n",
    "print(\"Cross-Validation Results:\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "cv_results = {}\n",
    "for model_name in trained_models.keys():\n",
    "    cv_result = forecaster.cross_validate_model(\n",
    "        model_name, \n",
    "        X_train, \n",
    "        y_train, \n",
    "        cv_folds=5\n",
    "    )\n",
    "    cv_results[model_name] = cv_result\n",
    "\n",
    "# Create CV comparison DataFrame\n",
    "cv_comparison = pd.DataFrame({\n",
    "    model: {'Mean CV RMSE': results['mean_rmse'], 'Std CV RMSE': results['std_rmse']}\n",
    "    for model, results in cv_results.items()\n",
    "}).T\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(cv_comparison)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Predictions Visualization for All Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot predictions for all models\n",
    "fig, axes = plt.subplots(2, 2, figsize=(18, 12))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for idx, (model_name, y_pred) in enumerate(model_predictions.items()):\n",
    "    if idx < 4:\n",
    "        ax = axes[idx]\n",
    "        \n",
    "        # Plot first 100 samples for clarity\n",
    "        sample_size = min(100, len(y_test))\n",
    "        indices = np.arange(sample_size)\n",
    "        \n",
    "        ax.plot(indices, y_test[:sample_size], label='Actual', alpha=0.8, linewidth=2)\n",
    "        ax.plot(indices, y_pred[:sample_size], label='Predicted', alpha=0.8, linewidth=2)\n",
    "        \n",
    "        ax.set_xlabel('Sample Index', fontsize=10)\n",
    "        ax.set_ylabel('Sales', fontsize=10)\n",
    "        ax.set_title(f'{model_name}', fontsize=12, fontweight='bold')\n",
    "        ax.legend(fontsize=9)\n",
    "        ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../results/visualizations/all_models_predictions.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Key Insights and Conclusions\n",
    "\n",
    "### Model Performance Summary\n",
    "Based on the evaluation metrics, we can draw the following conclusions:\n",
    "\n",
    "1. **Best Performing Model**: The model with the lowest RMSE provides the most accurate predictions\n",
    "\n",
    "2. **Feature Importance**: Key factors affecting sales include:\n",
    "   - Historical sales patterns (lag features)\n",
    "   - Seasonality (month, day of week)\n",
    "   - Holiday effects\n",
    "   - Rolling statistics\n",
    "\n",
    "3. **Seasonality Patterns**: \n",
    "   - Clear weekly patterns with weekend effects\n",
    "   - Monthly and seasonal variations\n",
    "   - Holiday-driven spikes\n",
    "\n",
    "4. **Model Complexity vs Performance**:\n",
    "   - Linear Regression provides a good baseline\n",
    "   - Tree-based models (Random Forest, Gradient Boosting, XGBoost) capture non-linear patterns better\n",
    "\n",
    "### Recommendations\n",
    "\n",
    "1. **Inventory Management**: Use predictions to optimize stock levels, especially around holidays\n",
    "2. **Promotional Planning**: Time promotions based on predicted low-sales periods\n",
    "3. **Staffing**: Adjust staffing levels based on predicted sales volume\n",
    "4. **Model Deployment**: The best model can be deployed for real-time forecasting\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "1. Fine-tune hyperparameters for better performance\n",
    "2. Incorporate external factors (weather, economic indicators)\n",
    "3. Implement ensemble methods combining multiple models\n",
    "4. Set up automated retraining pipeline\n",
    "5. Deploy model as a web service for real-time predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14. Save Models and Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save best model\n",
    "import os\n",
    "os.makedirs('../models', exist_ok=True)\n",
    "\n",
    "best_model_path = f'../models/{best_model_name.replace(\" \", \"_\")}_best_model.pkl'\n",
    "forecaster.save_model(best_model_name, best_model_path)\n",
    "\n",
    "print(f\"Best model ({best_model_name}) saved successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save comparison results\n",
    "os.makedirs('../results', exist_ok=True)\n",
    "comparison_df.to_csv('../results/model_comparison.csv')\n",
    "\n",
    "print(\"Model comparison results saved to ../results/model_comparison.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Conclusion\n",
    "\n",
    "This notebook demonstrated a complete end-to-end sales forecasting solution including:\n",
    "- Comprehensive data preprocessing and feature engineering\n",
    "- Multiple machine learning models for forecasting\n",
    "- Thorough evaluation and comparison\n",
    "- Feature importance analysis\n",
    "- Actionable insights for business decisions\n",
    "\n",
    "The modular code structure allows for easy customization and extension for specific business needs.\n",
    "\n",
    "**Project Repository**: [Sales-Forecasting](https://github.com/Harshitpal1/Sales-Forecasting)\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
